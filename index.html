<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Akash Kamalesh - Portfolio</title>
    <link rel="stylesheet" href="https://akash-kamalesh.github.io/style.css">
</head>
<body>
    <!-- Navigation Bar -->
    <nav class="navbar">
        <div class="nav-container">
            <a href="https://akash-kamalesh.github.io" class="nav-logo">Akash Kamalesh</a>
            <ul class="nav-menu">
                <li class="nav-item">
                    <a href="https://akash-kamalesh.github.io#about" class="nav-link">About</a>
                </li>
                <li class="nav-item">
                    <a href="https://akash-kamalesh.github.io#publications" class="nav-link">Publications</a>
                </li>
                <li class="nav-item">
                    <a href="https:&#x2F;&#x2F;drive.google.com&#x2F;file&#x2F;d&#x2F;1d4vC6TQfj081uj_moJvR9mB1Fl0kJqEB&#x2F;view?usp=sharing" class="nav-link" target="_blank">Resume</a>
                </li>
                <li class="nav-item">
                    <a href="https://akash-kamalesh.github.io/blog" class="nav-link">Blog</a>
                </li>
                <li class="nav-item">
                    <a href="https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?user=QUNjegoAAAAJ&amp;hl=en" class="nav-link" target="_blank" title="Google Scholar">
                        <img src="https://akash-kamalesh.github.io/google-scholar-brands-solid-full.svg" alt="Google Scholar" class="icon-img">
                    </a>
                </li>
                <li class="nav-item">
                    <a href="https:&#x2F;&#x2F;github.com&#x2F;akash-kamalesh" class="nav-link" target="_blank" title="GitHub">
                        <svg class="icon" viewBox="0 0 24 24" fill="currentColor">
                            <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v 3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                        </svg>
                    </a>
                </li>
                <li class="nav-item">
                    <a href="https:&#x2F;&#x2F;linkedin.com&#x2F;in&#x2F;akash-kamalesh" class="nav-link" target="_blank" title="LinkedIn">
                        <svg class="icon" viewBox="0 0 24 24" fill="currentColor">
                            <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.475-2.236-1.986-2.236-1.081 0-1.722.731-2.004 1.438-.103.249-.129.597-.129.946v5.421h-3.554s.05-8.736 0-9.646h3.554v1.364c.429-.659 1.196-1.597 2.905-1.597 2.12 0 3.71 1.386 3.71 4.365v5.514zM5.337 9.433c-1.144 0-1.915-.758-1.915-1.707 0-.955.77-1.708 1.963-1.708 1.192 0 1.915.753 1.94 1.708 0 .949-.748 1.707-1.988 1.707zm1.582 11.019H3.656V9.806h3.263v10.646zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.225 0z"/>
                        </svg>
                    </a>
                </li>
                <li class="nav-item">
                    <a href="mailto:akash.kamalesh03@gmail.com" class="nav-link" title="Email">
                        <svg class="icon" viewBox="0 0 24 24" fill="currentColor">
                            <path d="M20 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4l-8 5-8-5V6l8 5 8-5v2z"/>
                        </svg>
                    </a>
                </li>
            </ul>
        </div>
    </nav>

    <!-- Main Content -->
    <main id="top">
        
    <!-- Hero Section -->
    <section class="hero">
        <div class="hero-content">
            <div class="profile-image-container">
                <img src="https://akash-kamalesh.github.io/profile.jpg" alt="Profile" class="profile-image">
            </div>
            <h1 class="hero-name">Akash Kamalesh</h1>
            <p class="hero-subtitle">Software Engineer @Cisco | Prev. AI @IISc | Multimodal Reasoning and Reinforcement Learning</p>
        </div>
    </section>

    <!-- About Section -->
    <section id="about" class="about">
        <div class="container">
            <h2>About</h2>
            <div class="about-content">
                <p>
                    I'm a B.Tech Computer Science and Engineering graduate from PES University, Bengaluru. Currently conducting independent research on building scalable and efficient AI systems, with particular emphasis on <strong>representation learning, multimodal alignment, contrastive learning, and fine-tuning strategies for foundation models.</strong>
                </p>
                <p>
                    I've worked on methods like <strong>UnoLoRA</strong> for efficient multitask adaptation, explored grounding information better in vision-language models, and developed cross-lingual sparse <strong>Mixture of Experts</strong> architectures. My broader goal is to make foundation models more aligned, interpretable, and adaptable across tasks and modalities.
                </p>
                <p>
                    In addition to research, I've applied these ideas in real-world settings through roles at <strong>IISc</strong>, <strong>Swiggy</strong>, <strong>Nokia</strong>, and <strong>Cisco</strong>, where I worked on applying generative AI across practical domains such as finance and healthcare, building conversational recommender systems for personalized item suggestions and solving graph network problems.
                </p>
            </div>
        </div>
    </section>

    <!-- Projects Section -->
    <section id="projects" class="projects">
        <div class="container">
            <h2>Projects</h2>
            <div class="carousel-container">
                <button class="carousel-btn prev-btn" onclick="scrollCarousel(-1)">&#10094;</button>
                <div class="carousel-viewport">
                    <div class="projects-carousel">
                    <!-- Project Card 1 -->
                <div class="project-card">
                    <div class="project-image">
                        <img src="https://akash-kamalesh.github.io/nanovlm_lab_logo.png" alt="Project 1">
                    </div>
                    <div class="project-content">
                        <h3 class="project-title">NanoVLM Lab</h3>
                        <div class="project-buttons">
                            <button class="project-btn about-btn" onclick="openProjectDescription(event, 'project1Modal')">ABOUT</button>
                            <a href="https://github.com/akash-kamalesh/nanovlm-lab" class="project-btn github-btn" target="_blank">
                                <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor">
                                    <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v 3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                                </svg>
                            </a>
                        </div>
                    </div>
                </div>

                <!-- Project Card 2 -->
                <div class="project-card">
                    <div class="project-image">
                        <img src="https://akash-kamalesh.github.io/ntransformer_logo.png" alt="Project 2">
                    </div>
                    <div class="project-content">
                        <h3 class="project-title">TNT: The Normalized Transformer</h3>
                        <div class="project-buttons">
                            <button class="project-btn about-btn" onclick="openProjectDescription(event, 'project2Modal')">ABOUT</button>
                            <a href="https://github.com/akash-kamalesh/normalized-transformer" class="project-btn github-btn" target="_blank">
                                <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor">
                                    <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v 3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                                </svg>
                            </a>
                        </div>
                    </div>
                </div>

                <!-- Project Card 3 -->
                <div class="project-card">
                    <div class="project-image">
                        <img src="https://akash-kamalesh.github.io/baraat_logo.png" alt="Project 3">
                    </div>
                    <div class="project-content">
                        <h3 class="project-title">Project Baraat</h3>
                        <div class="project-buttons">
                            <button class="project-btn about-btn" onclick="openProjectDescription(event, 'project3Modal')">ABOUT</button>
                            <a href="https://github.com/akash-kamalesh/Baraat" class="project-btn github-btn" target="_blank">
                                <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor">
                                    <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v 3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                                </svg>
                            </a>
                        </div>
                    </div>
                </div>

                    </div>
                </div>
                <button class="carousel-btn next-btn" onclick="scrollCarousel(1)">&#10095;</button>
            </div>
        </div>
    </section>

    <!-- Project Description Modals -->
    <div id="project1Modal" class="modal" onclick="closeProjectDescription(event, 'project1Modal')">
        <div class="modal-content" onclick="event.stopPropagation()">
            <span class="close-btn" onclick="closeProjectDescription(null, 'project1Modal')">&times;</span>
            <h2>NanoVLM Lab</h2>
            <p>NanoVLM-Lab is an open-source training framework that democratizes vision-language model development for researchers and practitioners with limited computational resources. Built on HuggingFace's Transformers and TRL, it provides three powerful training approaches — Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Group Relative Policy Optimization (GRPO) — all optimized for efficient nanoVLM models. Whether you're working with a single T4 GPU or exploring cutting-edge alignment techniques, NanoVLM-Lab enables you to validate research ideas, build production-ready models, and iterate quickly without needing a supercomputer. The framework emphasizes accessibility, efficiency, and practical AI for everyone.</p>
        </div>
    </div>

    <div id="project2Modal" class="modal" onclick="closeProjectDescription(event, 'project2Modal')">
        <div class="modal-content" onclick="event.stopPropagation()">
            <span class="close-btn" onclick="closeProjectDescription(null, 'project2Modal')">&times;</span>
            <h2>TNT: The Normalized Transformer</h2>
            <p>TNT: The Normalized Transformer is a PyTorch implementation of an advanced transformer architecture that leverages normalization techniques and adaptive learning rates to improve training stability and performance on language modeling tasks. The model features a fully normalized encoder-decoder design with all embeddings and attention matrices constrained to a unit hypersphere, incorporates eigen-learning rates for dynamic balancing of self-attention, cross-attention, and feed-forward components, and achieves significant improvements on GLUE benchmarks (11.31% average improvement with up to 11.5% gain on WiC) while reducing parameters by 2.5% and validation loss by 7% within 2000 iterations.</p>
        </div>
    </div>

    <div id="project3Modal" class="modal" onclick="closeProjectDescription(event, 'project3Modal')">
        <div class="modal-content" onclick="event.stopPropagation()">
            <span class="close-btn" onclick="closeProjectDescription(null, 'project3Modal')">&times;</span>
            <h2>Project Baraat</h2>
            <p>Project Baraat is an open-source initiative dedicated to democratizing Large Language Models for Indic languages, with a focus on building continually pre-trained, task-specific language models using a Mixture of Experts (MoE) architecture. The project leverages diverse datasets including IndicCorp, Wikipedia articles, and augmented knowledge sources to pre-train base models (starting with LLaMa-2 7B) in multiple Indian languages like Hindi and Kannada, then fine-tunes them on downstream tasks including machine translation, mathematical reasoning, question answering, and instruction following. With robust tokenizers tailored for regional languages, high-quality cleaned datasets, and a commitment to open-source collaboration, Project Baraat aims to break language barriers and promote technological inclusivity by making advanced NLP capabilities accessible in native languages, while planning future expansions into multimodal learning, automated dataset cleaning pipelines, and enhanced reasoning abilities.</p>
        </div>
    </div>

    <!-- Publications Section -->
    <section id="publications" class="publications">
        <div class="container">
            <h2>Publications</h2>
            <div class="publications-list">
                <!-- Example Publication Card -->
                <div class="publication-card">
                    <div class="publication-image">
                        <img src="https://akash-kamalesh.github.io/isbi_preview.png" alt="Publication thumbnail">
                    </div>
                    <div class="publication-content">
                        <div class="publication-badge">ISBI 2026 (UNDER REVIEW)</div>
                        <h3 class="publication-title">Pixel-FLAIR: Leveraging Anatomical Segmentation for Region-Specific Supervision in Retinal Foundational Vision-Language Models</h3>
                        <p class="publication-authors">Sasidhar Alavala, Akash Kamalesh, Chandra Sekhar Seelamantula</p>
                        <p class="publication-venue"><em>23rd International Symposium on Biomedical Imaging (ISBI 2026)</em></p>
                        <div class="publication-links">
                            <button class="pub-btn abs-btn" onclick="openAbstract(event, 'abstract3Modal')">ABS</button>
                            <!-- <a href="https://openreview.net/pdf?id=n6W0QkQBgw" class="pub-btn" target="_blank">PDF</a> -->
                        </div>
                    </div>
                </div>

                <div class="publication-card">
                    <div class="publication-image">
                        <img src="https://akash-kamalesh.github.io/unolora_preview.png" alt="Publication thumbnail">
                    </div>
                    <div class="publication-content">
                        <div class="publication-badge">NeurIPS 2024</div>
                        <h3 class="publication-title">UnoLoRA: Single Low-Rank Adaptation for Efficient Multitask Fine-tuning</h3>
                        <p class="publication-authors">Akash Kamalesh, Anirudh Lakhotia, H S Nischal, Prerana Sanjay Kulkarni, and Gowri Srinivasa</p>
                        <p class="publication-venue"><em>Workshop on Fine-Tuning in Machine Learning at NeurIPS, 2024</em></p>
                        <div class="publication-links">
                            <button class="pub-btn abs-btn" onclick="openAbstract(event, 'abstractModal')">ABS</button>
                            <a href="https://openreview.net/pdf?id=n6W0QkQBgw" class="pub-btn" target="_blank">PDF</a>
                            <a href="https://neurips.cc/media/PosterPDFs/NeurIPS 2024/101671.png?t=1740678205.5010693" class="pub-btn" target="_blank">POSTER</a>
                            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QUNjegoAAAAJ&citation_for_view=QUNjegoAAAAJ:u-x6o8ySG0sC" class="pub-btn" target="_blank">GOOGLE SCHOLAR</a>
                        </div>
                    </div>
                </div>

                <div class="publication-card">
                    <div class="publication-image">
                        <img src="https://akash-kamalesh.github.io/iceeng_preview.png" alt="Publication thumbnail">
                    </div>
                    <div class="publication-content">
                        <div class="publication-badge">ICEENG 2025</div>
                        <h3 class="publication-title">Analysis of Sampling Strategies for Multi-Task Learning in Transformer Models</h3>
                        <p class="publication-authors">Anirudh Lakhotia, Akash Kamalesh, H S Nischal, Prerana Sanjay Kulkarni, and Gowri Srinivasa</p>
                        <p class="publication-venue"><em>2025 15th International Conference on Electrical Engineering (ICEENG)</em></p>
                        <div class="publication-links">
                            <button class="pub-btn abs-btn" onclick="openAbstract(event, 'abstract2Modal')">ABS</button>
                            <a href="https://ieeexplore.ieee.org/abstract/document/11031295" class="pub-btn" target="_blank">PDF</a>
                            <!-- <a href="https://neurips.cc/media/PosterPDFs/NeurIPS 2024/101671.png?t=1740678205.5010693" class="pub-btn" target="_blank">POSTER</a> -->
                            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QUNjegoAAAAJ&citation_for_view=QUNjegoAAAAJ:9yKSN-GCB0IC" class="pub-btn" target="_blank">GOOGLE SCHOLAR</a>
                        </div>
                    </div>
                </div>

                <!-- Add more publication cards as needed -->
            </div>
        </div>
    </section>

    <!-- Abstract Modal 1 - UnoLoRA -->
    <div id="abstractModal" class="modal" onclick="closeAbstract(event, 'abstractModal')">
        <div class="modal-content" onclick="event.stopPropagation()">
            <span class="close-btn" onclick="closeAbstract(null, 'abstractModal')">&times;</span>
            <h2>Abstract</h2>
            <p>
                Recent advances in Parameter-Efficient Fine-Tuning (PEFT) have shown Low-Rank Adaptation (LoRA) to be an effective implicit regularizer for large language models. Building on these findings, we propose UnoLoRA, a novel approach that leverages a single shared LoRA module for efficient multi-task learning. While existing methods typically use separate LoRA adaptations for each task, our approach demonstrates that a single shared adapter can effectively capture both task-specific and task-agnostic knowledge. We further introduce UnoLoRA*, an enhanced variant that employs a shared hypernetwork to generate task-specific embeddings, improving convergence and task adaptation. Our method significantly reduces trainable parameters to just 0.05% per task while maintaining competitive performance on the GLUE benchmark. Our analysis reveals that the A and B matrices in our shared LoRA adapter naturally develop complementary roles: A matrices capture generalizable features across tasks, while B matrices specialize in task-specific representations. Our results show that sharing a single LoRA adapter can achieve efficient multi-task learning while significantly reducing memory requirements, making it particularly valuable for resource-constrained applications.
            </p>
        </div>
    </div>

    <!-- Abstract Modal 2 - Sampling Strategies -->
    <div id="abstract2Modal" class="modal" onclick="closeAbstract(event, 'abstract2Modal')">
        <div class="modal-content" onclick="event.stopPropagation()">
            <span class="close-btn" onclick="closeAbstract(null, 'abstract2Modal')">&times;</span>
            <h2>Abstract</h2>
            <p>
                Multitask learning has emerged as a powerful paradigm for enhancing natural language understanding capabilities in large language models. However, the effectiveness of multitask learning heavily depends on the sampling strategy used to balance exposure to tasks of varying sizes and complexities during training. In this work, we conduct a comprehensive empirical analysis of three sampling strategies using T5-small on a subset of the GLUE benchmark: examples-proportional sampling, which samples based on raw dataset sizes; temperature-scaled sampling with T=10.0, which moderates size-based differences; and equal sampling, which gives uniform probability to all tasks. Our analysis examines the impact of these strategies on model performance, convergence patterns, task representation, and internal model dynamics through spectral analysis. Our results demonstrate that temperature-scaled sampling provides a strong balance between task representation and overall performance, while equal sampling achieves the highest average score across all tasks. Spectral analysis reveals that sampling strategies produce fundamentally different internal representations despite similar performance metrics, with higher temperatures promoting more uniform and stable layer behavior. We provide practical guidelines for selecting appropriate sampling strategies based on dataset characteristics, computational constraints, and specific training goals, contributing to more effective multitask learning approaches for language models.
            </p>
        </div>
    </div>

    <!-- Abstract Modal 3 - Pixel FLAIR -->
    <div id="abstract3Modal" class="modal" onclick="closeAbstract(event, 'abstract3Modal')">
        <div class="modal-content" onclick="event.stopPropagation()">
            <span class="close-btn" onclick="closeAbstract(null, 'abstract3Modal')">&times;</span>
            <h2>Abstract</h2>
            <p>
                Most current retinal foundational vision-language models do global image-text alignment, which often misses the subtle, localized features that are essential for early prescreening of retinal diseases. We propose Pixel-FLAIR, which offers better learned representations compared to FLAIR by incorporating a pixel-level text supervisory signal in addition to the standard image-level text supervisory signal. First, we use a segmentation model to find and extract key anatomical landmarks, which serve as anchors to automatically locate and extract clinically relevant sub-regions. We then pair these extracted image patches with their corresponding text labels. Then, the Pixel-FLAIR is fine-tuned using a contrastive loss where, for positive pairs, we modify the similarity score by combining the standard global image-text alignment score with a new, region-specific alignment score. Experiments show Pixel-FLAIR consistently outperforms the FLAIR baseline on classification tasks.
            </p>
        </div>
    </div>

    </main>

    <!-- Footer -->
    <footer class="footer">
        <p>&copy; 2025 Akash Kamalesh. All rights reserved.</p>
    </footer>

    <script>
        function openAbstract(event, modalId = 'abstractModal') {
            event.preventDefault();
            const modal = document.getElementById(modalId);
            if (modal) {
                modal.classList.add('active');
            }
        }

        function closeAbstract(event, modalId = 'abstractModal') {
            const modal = document.getElementById(modalId);
            if (modal) {
                modal.classList.remove('active');
            }
        }

        function openProjectDescription(event, modalId) {
            event.preventDefault();
            const modal = document.getElementById(modalId);
            if (modal) {
                modal.classList.add('active');
            }
        }

        function closeProjectDescription(event, modalId) {
            const modal = document.getElementById(modalId);
            if (modal) {
                modal.classList.remove('active');
            }
        }

        let carouselAutoScrollInterval;
        let currentProjectIndex = 0;

        function scrollCarousel(direction) {
            const carousel = document.querySelector('.projects-carousel');
            if (carousel) {
                const cards = carousel.querySelectorAll('.project-card');
                const totalCards = cards.length;
                
                currentProjectIndex += direction;
                
                if (currentProjectIndex >= totalCards) {
                    currentProjectIndex = 0;
                } else if (currentProjectIndex < 0) {
                    currentProjectIndex = totalCards - 1;
                }
                
                const carouselWidth = carousel.offsetWidth;
                const cardWidth = carouselWidth;
                const gap = 32;
                const translateAmount = (cardWidth + gap) * currentProjectIndex;
                
                carousel.style.transform = `translateX(-${translateAmount}px)`;
            }
        }

        function startCarouselAutoScroll() {
            carouselAutoScrollInterval = setInterval(() => {
                scrollCarousel(1);
            }, 3000);
        }

        function resetCarouselAutoScroll() {
            clearInterval(carouselAutoScrollInterval);
            startCarouselAutoScroll();
        }

        document.addEventListener('DOMContentLoaded', function() {
            startCarouselAutoScroll();
            
            const carouselBtns = document.querySelectorAll('.carousel-btn');
            carouselBtns.forEach(btn => {
                btn.addEventListener('click', resetCarouselAutoScroll);
            });

            const carouselViewport = document.querySelector('.carousel-viewport');
            if (carouselViewport) {
                carouselViewport.addEventListener('mouseenter', function() {
                    clearInterval(carouselAutoScrollInterval);
                });
                carouselViewport.addEventListener('mouseleave', function() {
                    startCarouselAutoScroll();
                });
            }
        });

        // Close modal when pressing Escape key
        document.addEventListener('keydown', function(event) {
            if (event.key === 'Escape') {
                // Close all open modals
                const modals = document.querySelectorAll('.modal.active');
                modals.forEach(modal => {
                    modal.classList.remove('active');
                });
            }
        });
    </script>
</body>
</html>
